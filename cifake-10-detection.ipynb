{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 13.8463,
     "end_time": "2024-03-23T15:39:27.261114",
     "exception": false,
     "start_time": "2024-03-23T15:39:13.414814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.activations import swish\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.013897,
     "end_time": "2024-03-23T15:39:27.281716",
     "exception": false,
     "start_time": "2024-03-23T15:39:27.267819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NAME = \"cifakeCNN{}\".format(time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.309483,
     "end_time": "2024-03-23T15:39:27.598333",
     "exception": false,
     "start_time": "2024-03-23T15:39:27.288850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Number of GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"/kaggle/input/cifar-10-fake-image-dataset/cifar-10-dataset\" #! Kaggle path\n",
    "working_dir = \"/kaggle/working\" #! Kaggle path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.013049,
     "end_time": "2024-03-23T15:39:27.617926",
     "exception": false,
     "start_time": "2024-03-23T15:39:27.604877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gpus = tf.config.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#   # \"\"\"Restrict TensorFlow to only allocate 1GB of memory on the first GPU\"\"\"\n",
    "#   try:\n",
    "#     tf.config.set_logical_device_configuration(\n",
    "#         gpus[0],\n",
    "#         [tf.config.LogicalDeviceConfiguration(memory_limit=1024)])\n",
    "#     logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "#     print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "#   except RuntimeError as e:\n",
    "#     # Virtual devices must be set before GPUs have been initialized\n",
    "#     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.012325,
     "end_time": "2024-03-23T15:39:27.636598",
     "exception": false,
     "start_time": "2024-03-23T15:39:27.624273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#! \"\"\"When running locally, limits the threads to 1 (only uses one thread of one CPU core)\"\"\"\n",
    "# tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "# tf.config.threading.set_inter_op_parallelism_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! \"\"\"When running on Kaggle, copies the input directory cifake_hyperband to the working directory for tuner continuity / cumulative session training.\"\"\"\n",
    "# from distutils.dir_util import copy_tree\n",
    "# source_dir = \"/kaggle/input/cifake_hyperband/\"\n",
    "# destination_dir = \"/kaggle/working/\"\n",
    "# copy_tree(source_dir, destination_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 102.868315,
     "end_time": "2024-03-23T15:41:10.511164",
     "exception": false,
     "start_time": "2024-03-23T15:39:27.642849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_train = image_dataset_from_directory(\n",
    "    f'{input_dir}/train',\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=[32,32],\n",
    "    interpolation='nearest',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "#     seed=69,\n",
    "    #validation_split=None,\n",
    "    subset=None,\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 18.002093,
     "end_time": "2024-03-23T15:41:28.519977",
     "exception": false,
     "start_time": "2024-03-23T15:41:10.517884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_test = image_dataset_from_directory(\n",
    "    f'{input_dir}/test',\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=[32,32],\n",
    "    interpolation='nearest',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "#     seed=69,\n",
    "    #validation_split=None,\n",
    "    subset=None,\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.01465,
     "end_time": "2024-03-23T15:41:28.541426",
     "exception": false,
     "start_time": "2024-03-23T15:41:28.526776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_to_float(image, label):\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    return image, label\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.06361,
     "end_time": "2024-03-23T15:41:28.611485",
     "exception": false,
     "start_time": "2024-03-23T15:41:28.547875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_train = (\n",
    "    ds_train\n",
    "    .map(convert_to_float)\n",
    "    .cache()\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.025031,
     "end_time": "2024-03-23T15:41:28.643178",
     "exception": false,
     "start_time": "2024-03-23T15:41:28.618147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_valid = (\n",
    "    ds_test\n",
    "    .map(convert_to_float)\n",
    "    .cache()\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.013521,
     "end_time": "2024-03-23T15:41:28.663108",
     "exception": false,
     "start_time": "2024-03-23T15:41:28.649587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backup_dir = f\"{working_dir}/backup/latest\"\n",
    "backup_callback = keras.callbacks.BackupAndRestore(\n",
    "    backup_dir, save_freq=\"epoch\", delete_checkpoint=True\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LearningRateScheduler\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 11:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * 0.98\n",
    "\n",
    "schedule_lr = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.013319,
     "end_time": "2024-03-23T15:41:28.702897",
     "exception": false,
     "start_time": "2024-03-23T15:41:28.689578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "# timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "# model_checkpoint = ModelCheckpoint(\n",
    "#     f'/kaggle/working/best/best_model_{timestamp}.keras', monitor='val_loss', save_best_only=True, mode='min'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=7, min_lr=0.0008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.191459,
     "end_time": "2024-03-23T15:41:28.900860",
     "exception": false,
     "start_time": "2024-03-23T15:41:28.709401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def MBConv6(input_tensor, hp=None, out_channels=32, expansion=6, squeezing=4, use_se=True, dropout_rate=0.0):\n",
    "    # inverted residual structure\n",
    "    # pointwise convolution 1 expansion\n",
    "    x = layers.Conv2D(expansion * input_tensor.shape[-1], (1,  1), padding='same', use_bias=False)(input_tensor)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(swish)(x)\n",
    "\n",
    "    # Depthwise Separable Convolution \n",
    "    x = layers.DepthwiseConv2D(kernel_size=(3,  3), strides=(1,  1), padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(swish)(x)\n",
    "\n",
    "    # pointwise convolution 2 bottleneck\n",
    "    x = layers.Conv2D(out_channels, (1,  1), padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # Dropout\n",
    "    if dropout_rate >  0.0:\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    # bottleneck\n",
    "    x = layers.Conv2D(out_channels, (1,  1), padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # Squeeze-and-Excitation\n",
    "    if use_se:\n",
    "        se_shape = (1,  1, out_channels)\n",
    "        se = layers.GlobalAveragePooling2D()(x)\n",
    "        se = layers.Reshape(se_shape)(se)\n",
    "        se = layers.Conv2D(out_channels // squeezing, (1,  1), padding='same', use_bias=True)(se)\n",
    "        se = layers.Activation(swish)(se)\n",
    "        se = layers.Conv2D(out_channels, (1,  1), padding='same', use_bias=True)(se)\n",
    "        se = layers.Activation('sigmoid')(se)\n",
    "        x = layers.Multiply()([x, se])\n",
    "\n",
    "    # Residual\n",
    "    if input_tensor.shape[-1] == out_channels:\n",
    "        shortcut = input_tensor\n",
    "    else:\n",
    "        shortcut = layers.Conv2D(out_channels, (1,  1), strides=(1,  1), padding='same', use_bias=False)(input_tensor)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "    x = layers.Add()([x, shortcut])\n",
    "\n",
    "    return x\n",
    "input_tensor = layers.Input(shape=(32,  32,  16)) \n",
    "output_tensor = MBConv6(input_tensor)\n",
    "model = keras.models.Model(inputs=input_tensor, outputs=output_tensor)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.132116,
     "end_time": "2024-03-23T15:41:29.040757",
     "exception": false,
     "start_time": "2024-03-23T15:41:28.908641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def MBConv1(input_tensor, hp=None, expansion=4, squeezing=4, out_channels=16, strides=(1,   1), use_se=True):\n",
    "\n",
    "    x = layers.Conv2D(expansion, (1,   1), padding='same', use_bias=False)(input_tensor)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(swish)(x)\n",
    "\n",
    "\n",
    "    x = layers.DepthwiseConv2D(kernel_size=(3,   3), strides=strides, padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(swish)(x) \n",
    "\n",
    "\n",
    "    x = layers.Conv2D(out_channels, (1,   1), padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # Squeeze-and-Excitation\n",
    "    if use_se:\n",
    "        se_shape = (1,  1, out_channels)\n",
    "        se = layers.GlobalAveragePooling2D()(x)\n",
    "        se = layers.Reshape((1,  1, out_channels))(se) \n",
    "        se = layers.Conv2D(out_channels //  squeezing, (1,  1), padding='same', use_bias=True)(se) \n",
    "        se = layers.Activation(swish)(se)   \n",
    "        se = layers.Conv2D(out_channels, (1,  1), padding='same', use_bias=True)(se) \n",
    "        se = layers.Activation('sigmoid')(se)\n",
    "        se = layers.Reshape(se_shape[1:])(se)  # Reshape to original\n",
    "        x = layers.Multiply()([x, se])\n",
    "\n",
    "    # Residual\n",
    "    if input_tensor.shape[-1] == out_channels and strides == (1,   1):\n",
    "        x = layers.Add()([x, input_tensor])\n",
    "    else:\n",
    "        input_tensor = layers.Conv2D(out_channels, (1,   1), strides=strides, padding='same', use_bias=False)(input_tensor)\n",
    "        x = layers.Add()([x, input_tensor])\n",
    "\n",
    "    return x\n",
    "\n",
    "input_tensor = layers.Input(shape=(32,  32,  3)) \n",
    "output_tensor = MBConv1(input_tensor)\n",
    "model = keras.models.Model(inputs=input_tensor, outputs=output_tensor)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1.3997,
     "end_time": "2024-03-23T15:41:30.449198",
     "exception": false,
     "start_time": "2024-03-23T15:41:29.049498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import keras_tuner\n",
    "from keras_tuner import RandomSearch, Hyperband\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.metrics import Accuracy, Precision, Recall, F1Score\n",
    "\n",
    "def build_model(hp=None):\n",
    "    activation_function = activation=hp.Choice('ACTIVATION', values=['swish', 'gelu', 'silu'])\n",
    "    \n",
    "    input_tensor = layers.Input(shape=[32,  32,  3])\n",
    "    x = layers.Reshape(target_shape=(32, 32, 3))(input_tensor)\n",
    "    \n",
    "    # x = layers.RandomRotation(factor=0.1488228133769420)(input_tensor)\n",
    "    x = layers.RandomTranslation(\n",
    "        height_factor=hp.Float('height_factor', min_value=0.0001, max_value=0.1, sampling='log'),\n",
    "        width_factor=hp.Float('width_factor', min_value=0.0001, max_value=0.1, sampling='log')\n",
    "    )(x)\n",
    "    if hp.Boolean('PREPROCESSING_horizontal'):\n",
    "        x = layers.RandomFlip(mode='horizontal')(x)\n",
    "    # x = layers.BatchNormalization()(x)\n",
    "    if hp.Boolean('PRECONV_norm'):\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # x = MBConv1(x, hp=hp)\n",
    "    num_conv_layers = hp.Int('num_conv_layers', min_value=2, max_value=5, step=1)\n",
    "    max_pool_layers = hp.Int('max_pool_layers', min_value=0, max_value=num_conv_layers-1, step=1)\n",
    "    batch_norm_layers = hp.Int('batch_norm_layers', min_value=2, max_value=num_conv_layers, step=1)\n",
    "\n",
    "    max_pool_assigned = [0] * num_conv_layers\n",
    "    batch_norm_assigned = [0] * num_conv_layers\n",
    "\n",
    "    unassigned_indices_max_pool = set(range(num_conv_layers))\n",
    "    unassigned_indices_batch_norm = set(range(num_conv_layers))\n",
    "\n",
    "    for _ in range(max_pool_layers):\n",
    "        index = np.random.choice(list(unassigned_indices_max_pool))\n",
    "        max_pool_assigned[index] = 1\n",
    "        unassigned_indices_max_pool.remove(index)\n",
    "\n",
    "    for _ in range(batch_norm_layers):\n",
    "        index = np.random.choice(list(unassigned_indices_batch_norm))\n",
    "        batch_norm_assigned[index] = 1\n",
    "        unassigned_indices_batch_norm.remove(index)\n",
    "\n",
    "    for i in range(num_conv_layers):\n",
    "        x = layers.Conv2D(filters=hp.Int(f'conv_{i}_filter', min_value=42, max_value=54, step=6),\n",
    "                                 kernel_size=hp.Choice(f'conv_{i}_kernel', values=[3, 4, 5]),\n",
    "                                 activation=activation_function, padding='same',\n",
    "                                 kernel_regularizer=keras.regularizers.l2(0.003) if hp.Boolean('l2_reg') else None)(x)\n",
    "        x = layers.Dropout(hp.Float(f'CONV_dropout_{i}_rate', min_value=0.0, max_value=0.3, step=0.1))(x)\n",
    "\n",
    "        if max_pool_assigned[i] == 1:\n",
    "            x = layers.MaxPool2D()(x)\n",
    "        if batch_norm_assigned[i] == 1:\n",
    "            x = layers.BatchNormalization()(x)\n",
    "        \n",
    "    \n",
    "    \n",
    "    if hp.Boolean('use_maxpool_final'):\n",
    "        x = layers.MaxPool2D()(x)\n",
    "    if hp.Boolean('use_batchnorm_final'):\n",
    "        x = layers.BatchNormalization()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "\n",
    "    for i in range(hp.Int('num_dense_layers', min_value=6, max_value=12, step=1)):   \n",
    "        x = layers.Dense(hp.Int(f'dense_{i}_units', min_value=444, max_value=544, step=32),\n",
    "                         activation=activation_function,\n",
    "                         kernel_regularizer=keras.regularizers.l2(0.003) if hp.Boolean('l2_reg') else None)(x)\n",
    "        x = layers.Dropout(hp.Float(f'dropout_{i}_rate', min_value=0.0, max_value=0.6, step=0.1))(x)\n",
    "    \n",
    "    x = layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    optimizer_choice = hp.Choice('optimizer', values=['Adagrad', 'Adadelta', 'Adamax'])\n",
    "    \n",
    "    if optimizer_choice == 'Adamax':\n",
    "        optimizer = tf.keras.optimizers.Adamax(learning_rate=hp.Float('adamax_learning_rate', min_value=0.0018, max_value=0.0098, sampling='LOG'))\n",
    "    elif optimizer_choice == 'Adadelta':\n",
    "        optimizer = tf.keras.optimizers.Adadelta(learning_rate=hp.Float('adadelta_learning_rate', min_value=0.0018, max_value=0.0098, sampling='LOG'))\n",
    "    elif optimizer_choice == 'Adagrad':\n",
    "        optimizer = tf.keras.optimizers.Adagrad(learning_rate=hp.Float('adagrad_learning_rate', min_value=0.0018, max_value=0.0098, sampling='LOG'))\n",
    "  \n",
    "    \n",
    "    model = Model(inputs=input_tensor, outputs=x)\n",
    "\n",
    "    \n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['binary_accuracy', \n",
    "                      Precision(name='precision'), \n",
    "                      Recall(name='recall'), \n",
    "                      F1Score(name='f1_score')])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.175897,
     "end_time": "2024-03-23T15:41:30.633936",
     "exception": false,
     "start_time": "2024-03-23T15:41:30.458039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuner = Hyperband(\n",
    "    build_model,\n",
    "    objective='val_binary_accuracy', \n",
    "    max_epochs=13,\n",
    "    factor=3,\n",
    "    directory=f'{working_dir}/projects',\n",
    "    project_name='cifake_hyperband')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 27154.821941,
     "end_time": "2024-03-23T23:14:05.464891",
     "exception": false,
     "start_time": "2024-03-23T15:41:30.642950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Start the hyperparameter search with early stopping\n",
    "tuner.search(ds_train, epochs=13, validation_data=ds_valid, callbacks=[early_stopping, tensorboard, reduce_lr, schedule_lr, backup_callback]) #, verbose=0 model_checkpoint\n",
    "\n",
    "best_model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.083178,
     "end_time": "2024-03-23T23:14:05.558641",
     "exception": false,
     "start_time": "2024-03-23T23:14:05.475463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.021383,
     "end_time": "2024-03-23T23:14:05.590357",
     "exception": false,
     "start_time": "2024-03-23T23:14:05.568974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.131977,
     "end_time": "2024-03-23T23:14:05.733002",
     "exception": false,
     "start_time": "2024-03-23T23:14:05.601025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model.save(f\"{working_dir}/BEST{NAME}.keras\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3041726,
     "sourceId": 5256696,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4500471,
     "sourceId": 7708047,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30683,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 27299.651207,
   "end_time": "2024-03-23T23:14:10.167668",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-23T15:39:10.516461",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
