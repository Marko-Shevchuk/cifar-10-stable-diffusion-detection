{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d533844-a5c2-4eb1-acb9-39b4eb35541c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.activations import swish\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "025df5b5-879d-484a-8e65-c6ec8a460f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"cifakeCNN{}\".format(time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f54081e-a82d-47aa-ac54-cf9c939b8ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "738b03bc-735b-4cd5-b348-63d0d6bfbdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpus = tf.config.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#   # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "#   try:\n",
    "#     tf.config.set_logical_device_configuration(\n",
    "#         gpus[0],\n",
    "#         [tf.config.LogicalDeviceConfiguration(memory_limit=1024)])\n",
    "#     logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "#     print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "#   except RuntimeError as e:\n",
    "#     # Virtual devices must be set before GPUs have been initialized\n",
    "#     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e35b286-a38e-45fb-851e-d6e9eaf3f830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "# tf.config.threading.set_inter_op_parallelism_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09f475bf-79e8-4f3f-9c7c-89c328e0b6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "ds_train = image_dataset_from_directory(\n",
    "    '../cifar-10-stable-diffusion-detection/train',\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=[32,32],\n",
    "    interpolation='nearest',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=69,\n",
    "    #validation_split=None,\n",
    "    subset=None,\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3911311e-1e50-475d-91e7-1dc099915515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "ds_test = image_dataset_from_directory(\n",
    "    '../cifar-10-stable-diffusion-detection/test',\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=[32,32],\n",
    "    interpolation='nearest',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=69,\n",
    "    #validation_split=None,\n",
    "    subset=None,\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f0a0dea-309a-43a0-9feb-2a45ae9dd40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_float(image, label):\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    return image, label\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "584741db-e277-44ef-a9ff-17451da9e3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = (\n",
    "    ds_train\n",
    "    .map(convert_to_float)\n",
    "    .cache()\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6dbddc2-592c-400a-aab0-21c834302d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_valid = (\n",
    "    ds_test\n",
    "    .map(convert_to_float)\n",
    "    .cache()\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be73946f-d529-4ba7-b614-3cd6a56ec098",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=8,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a494b31-1b27-4018-aced-9de136d2bc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, min_lr=0.0008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8790dc24-8d76-49ab-96aa-12cdc9363217",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    f'best/best_model_{timestamp}.keras', monitor='val_loss', save_best_only=True, mode='min'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6c73140-66a4-46a2-bc33-fef58a532b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 32, 32, 16)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 32, 32, 96)   1536        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 32, 32, 96)  384         ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 32, 32, 96)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " depthwise_conv2d (DepthwiseCon  (None, 32, 32, 96)  864         ['activation[0][0]']             \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 32, 32, 96)  384         ['depthwise_conv2d[0][0]']       \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 32, 32, 96)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 32, 32, 32)   3072        ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 32, 32, 32)  128         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 32, 32, 32)   1024        ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 32, 32, 32)  128         ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 32)          0           ['batch_normalization_3[0][0]']  \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1, 32)     0           ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 1, 1, 8)      264         ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 1, 1, 8)      0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 1, 1, 32)     288         ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 1, 1, 32)     0           ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 32, 32, 32)   512         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 32, 32, 32)   0           ['batch_normalization_3[0][0]',  \n",
      "                                                                  'activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 32, 32, 32)  128         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 32, 32, 32)   0           ['multiply[0][0]',               \n",
      "                                                                  'batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,712\n",
      "Trainable params: 8,136\n",
      "Non-trainable params: 576\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def MBConv6(input_tensor, hp=None, out_channels=32, expansion=6, use_se=True, dropout_rate=0.0):\n",
    "    # Inverted Residual Structure\n",
    "    # Pointwise Convolution  1 with Expansion Factor  6\n",
    "    x = layers.Conv2D(expansion * input_tensor.shape[-1], (1,  1), padding='same', use_bias=False)(input_tensor)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(swish)(x)\n",
    "\n",
    "    # Depthwise Separable Convolution with stride (1,  1)\n",
    "    x = layers.DepthwiseConv2D(kernel_size=(3,  3), strides=(1,  1), padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(swish)(x)\n",
    "\n",
    "    # Pointwise Convolution  2\n",
    "    x = layers.Conv2D(out_channels, (1,  1), padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # Dropout\n",
    "    if dropout_rate >  0.0:\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    # Bottleneck Convolution  \n",
    "    x = layers.Conv2D(out_channels, (1,  1), padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # Squeeze-and-Excitation\n",
    "    if use_se:\n",
    "        se_shape = (1,  1, out_channels)\n",
    "        se = layers.GlobalAveragePooling2D()(x)\n",
    "        se = layers.Reshape(se_shape)(se)\n",
    "        se = layers.Conv2D(out_channels //  4, (1,  1), padding='same', use_bias=True)(se)\n",
    "        se = layers.Activation(swish)(se)\n",
    "        se = layers.Conv2D(out_channels, (1,  1), padding='same', use_bias=True)(se)\n",
    "        se = layers.Activation('sigmoid')(se)\n",
    "        x = layers.Multiply()([x, se])\n",
    "\n",
    "    # Residual\n",
    "    if input_tensor.shape[-1] == out_channels:\n",
    "        shortcut = input_tensor\n",
    "    else:\n",
    "        shortcut = layers.Conv2D(out_channels, (1,  1), strides=(1,  1), padding='same', use_bias=False)(input_tensor)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "    x = layers.Add()([x, shortcut])\n",
    "\n",
    "    return x\n",
    "input_tensor = layers.Input(shape=(32,  32,  16)) \n",
    "output_tensor = MBConv6(input_tensor)\n",
    "model = keras.models.Model(inputs=input_tensor, outputs=output_tensor)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa94a845-22cd-4ada-b4ea-3c633988fc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 32, 32, 4)    12          ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 32, 32, 4)   16          ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 32, 32, 4)    0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " depthwise_conv2d_1 (DepthwiseC  (None, 32, 32, 4)   36          ['activation_4[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 32, 32, 4)   16          ['depthwise_conv2d_1[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 32, 32, 4)    0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 32, 32, 16)   64          ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1 (Gl  (None, 16)          0           ['batch_normalization_7[0][0]']  \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 1, 1, 16)     0           ['global_average_pooling2d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 1, 1, 8)      136         ['reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 1, 1, 8)      0           ['conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 1, 1, 16)     144         ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 1, 1, 16)     0           ['conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)            (None, 1, 16)        0           ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)          (None, 32, 32, 16)   0           ['batch_normalization_7[0][0]',  \n",
      "                                                                  'reshape_2[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 32, 32, 16)   48          ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 32, 32, 16)   0           ['multiply_1[0][0]',             \n",
      "                                                                  'conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 536\n",
      "Trainable params: 488\n",
      "Non-trainable params: 48\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def MBConv1(input_tensor, hp=None, expansion=4, out_channels=16, strides=(1,   1), use_se=True):\n",
    "    # Expansion\n",
    "    x = layers.Conv2D(expansion, (1,   1), padding='same', use_bias=False)(input_tensor)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(swish)(x)\n",
    "\n",
    "    # Depthwise \n",
    "    x = layers.DepthwiseConv2D(kernel_size=(3,   3), strides=strides, padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(swish)(x) \n",
    "\n",
    "    # Pointwise \n",
    "    x = layers.Conv2D(out_channels, (1,   1), padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # Squeeze-and-Excitation\n",
    "    if use_se:\n",
    "        se_shape = (1,  1, out_channels)\n",
    "        se = layers.GlobalAveragePooling2D()(x)\n",
    "        se = layers.Reshape((1,  1, out_channels))(se) \n",
    "        se = layers.Conv2D(out_channels //  2, (1,  1), padding='same', use_bias=True)(se) \n",
    "        se = layers.Activation(swish)(se)   \n",
    "        se = layers.Conv2D(out_channels, (1,  1), padding='same', use_bias=True)(se) \n",
    "        se = layers.Activation('sigmoid')(se)\n",
    "        se = layers.Reshape(se_shape[1:])(se)  # Reshape to original\n",
    "        x = layers.Multiply()([x, se])\n",
    "\n",
    "    # Residual\n",
    "    if input_tensor.shape[-1] == out_channels and strides == (1,   1):\n",
    "        x = layers.Add()([x, input_tensor])\n",
    "    else:\n",
    "        input_tensor = layers.Conv2D(out_channels, (1,   1), strides=strides, padding='same', use_bias=False)(input_tensor)\n",
    "        x = layers.Add()([x, input_tensor])\n",
    "\n",
    "    return x\n",
    "\n",
    "input_tensor = layers.Input(shape=(32,  32,  3)) \n",
    "output_tensor = MBConv1(input_tensor)\n",
    "model = keras.models.Model(inputs=input_tensor, outputs=output_tensor)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "467e536e-01cf-4ac8-a0c0-f5ce0690d550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner\n",
    "from keras_tuner import RandomSearch\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def build_model(hp=None):\n",
    "    activation_function = 'leaky_relu' if hp.Boolean(f'use_leaky_relu_conv') else 'relu'\n",
    "    input_tensor = layers.Input(shape=[32,  32,  3])\n",
    "    \n",
    "    x = layers.experimental.preprocessing.RandomRotation(factor=0.1488228133769420)(input_tensor)\n",
    "    x = layers.experimental.preprocessing.RandomTranslation(height_factor=0.069, width_factor=0.069)(x)\n",
    "    x = layers.experimental.preprocessing.RandomFlip(mode='horizontal')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "\n",
    "    x = MBConv1(x, hp=hp)\n",
    "    x = MBConv6(input_tensor, hp=hp, out_channels=hp.Int('out_channels', min_value=28, max_value=36, step=4),\n",
    "                expansion=hp.Int('expansion', min_value=4, max_value=8, step=2),\n",
    "                use_se=hp.Boolean('use_se'),\n",
    "                dropout_rate=hp.Float('conv6_dropout_rate', min_value=0.0, max_value=0.2, step=0.1))\n",
    "    x = MBConv6(input_tensor, hp=hp, out_channels=hp.Int('out_channels', min_value=28, max_value=36, step=4),\n",
    "                expansion=hp.Int('expansion', min_value=4, max_value=8, step=2),\n",
    "                use_se=hp.Boolean('use_se'),\n",
    "                dropout_rate=hp.Float('conv6_dropout_rate', min_value=0.0, max_value=0.2, step=0.1))\n",
    "    x = MBConv6(input_tensor, hp=hp, out_channels=hp.Int('out_channels', min_value=28, max_value=36, step=4),\n",
    "                expansion=hp.Int('expansion', min_value=4, max_value=8, step=2),\n",
    "                use_se=hp.Boolean('use_se'),\n",
    "                dropout_rate=hp.Float('conv6_dropout_rate', min_value=0.0, max_value=0.2, step=0.1))\n",
    "    if hp.Boolean('use_maxpool'):\n",
    "        x = layers.MaxPool2D()(x)\n",
    "\n",
    "    x = layers.Conv2D(filters=hp.Int('conv_filter', min_value=2, max_value=4, step=2),\n",
    "                      kernel_size=hp.Choice('conv_kernel', values=[3,  7]),\n",
    "                      activation=activation_function, padding='same',\n",
    "                      kernel_regularizer=layers.regularizers.l2(0.002) if hp.Boolean('l2_reg') else None)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    if hp.Boolean('use_maxpool'):\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        x = layers.Conv2D(filters=hp.Int('conv_filter', min_value=2, max_value=4, step=2),\n",
    "                      kernel_size=hp.Choice('conv_kernel', values=[3,  7]),\n",
    "                      activation=activation_function, padding='same',\n",
    "                      kernel_regularizer=layers.regularizers.l2(0.002) if hp.Boolean('l2_reg') else None)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    if hp.Boolean('use_maxpool'):\n",
    "        x = layers.MaxPool2D()(x)s\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(filters=hp.Int('conv_filter', min_value=2, max_value=4, step=2),\n",
    "                      kernel_size=hp.Choice('conv_kernel', values=[3,  7]),\n",
    "                      activation=activation_function, padding='same',\n",
    "                      kernel_regularizer=layers.regularizers.l2(0.002) if hp.Boolean('l2_reg') else None)(x)\n",
    "    x = layers.MaxPool2D()(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    activation_function = 'leaky_relu' if hp.Boolean(f'use_leaky_relu_dense') else 'relu'\n",
    "    for i in range(hp.Int('num_dense_layers', min_value=0, max_value=4, step=2)):   \n",
    "        x = layers.Dense(hp.Int(f'dense_{i+1}_units', min_value=1, max_value=513, step=256),\n",
    "                         activation=activation_function,\n",
    "                         kernel_regularizer=layers.regularizers.l2(0.002) if hp.Boolean('l2_reg') else None)(x)\n",
    "        x = layers.Dropout(hp.Float(f'dropout_{i+1}_rate', min_value=0.0, max_value=0.5, step=0.1))(x)\n",
    "    \n",
    "    x = layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=hp.Float('learning_rate', min_value=0.001, max_value=0.1, sampling='LOG'),\n",
    "                                         epsilon=0.01)\n",
    "    model = Model(inputs=input_tensor, outputs=x)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['binary_accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d783dab-8ba2-4867-bbe4-46df27dc3660",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_binary_accuracy',\n",
    "    max_trials=42,\n",
    "    executions_per_trial=3,\n",
    "    directory='projects',\n",
    "    project_name='cifake5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42333f46-c4ec-4543-bfff-bdd2e6065a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "True              |True              |use_leaky_relu_conv\n",
      "28                |28                |out_channels\n",
      "6                 |6                 |expansion\n",
      "False             |False             |use_se\n",
      "0                 |0                 |conv6_dropout_rate\n",
      "True              |True              |use_maxpool\n",
      "4                 |4                 |conv_filter\n",
      "7                 |7                 |conv_kernel\n",
      "False             |False             |l2_reg\n",
      "False             |False             |use_leaky_relu_dense\n",
      "2                 |2                 |num_dense_layers\n",
      "0.0012163         |0.0012163         |learning_rate\n",
      "\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "Epoch 1/50\n",
      " 418/3125 [===>..........................] - ETA: 8:41 - loss: 0.6931 - binary_accuracy: 0.5061"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Start the hyperparameter search with early stopping\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensorboard\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_checkpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m best_model \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mget_best_models(num_models\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\miniconda3_2\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:233\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    230\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[1;32m--> 233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_run_and_update_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[1;32m~\\miniconda3_2\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:273\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 273\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_and_update_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[0;32m    274\u001b[0m         trial\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m trial_module\u001b[38;5;241m.\u001b[39mTrialStatus\u001b[38;5;241m.\u001b[39mCOMPLETED\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3_2\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:238\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[1;32m--> 238\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_trial(trial\u001b[38;5;241m.\u001b[39mtrial_id)\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mexists(\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m    241\u001b[0m     ):\n\u001b[0;32m    242\u001b[0m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[0;32m    243\u001b[0m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[0;32m    245\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    246\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe use case of calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    253\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    254\u001b[0m         )\n",
      "File \u001b[1;32m~\\miniconda3_2\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    312\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[0;32m    313\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[1;32m--> 314\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_and_fit_model(trial, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    316\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[1;32m~\\miniconda3_2\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py:233\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    231\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[0;32m    232\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[1;32m--> 233\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhypermodel\u001b[38;5;241m.\u001b[39mfit(hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    235\u001b[0m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_backend():\n",
      "File \u001b[1;32m~\\miniconda3_2\\lib\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py:149\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[1;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \n\u001b[0;32m    128\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3_2\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\miniconda3_2\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\miniconda3_2\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\miniconda3_2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\miniconda3_2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\miniconda3_2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3_2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\miniconda3_2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\miniconda3_2\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Start the hyperparameter search with early stopping\n",
    "tuner.search(ds_train, epochs=50, validation_data=ds_valid, callbacks=[early_stopping, tensorboard, reduce_lr, model_checkpoint])\n",
    "\n",
    "best_model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca23a7af-ab5a-48fc-8a0b-a837022d96b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea9ec7f-bf10-4492-9247-4a0546b62b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c88ad00-7106-4749-9f91-d829145e65ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "hyperparameters_str = \"_\".join(f\"{k}={v}__\" for k, v in best_hyperparameters.get_config().items())\n",
    "NAME += \"_\" + hyperparameters_str\n",
    "\n",
    "best_model.save(f\"best/{NAME}.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdead24-a3f7-4d78-be3d-e3b39890ab2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cputensorflow",
   "language": "python",
   "name": "cputensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
